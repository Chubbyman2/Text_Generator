{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generator_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOO97v8ixnfskP2Fp1V1WtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chubbyman2/Text_Generator/blob/master/Text_Generator_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKWW0dRQQCiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using LSTM model to generate text after training on a sample text\n",
        "# Sample text used is Shakespeare's King Lear"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADUFmnjtVDgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsnOOFWoS2TO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8751466c-5a31-4636-b8f7-9292a57553f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRizdFZZQL2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data preparation\n",
        "# 2 dicts - map char to int and int to char\n",
        "text_file = \"/content/gdrive/My Drive/king_lear.txt\"\n",
        "\n",
        "\n",
        "with open(text_file, \"r\") as file:\n",
        "  text = file.read().lower()\n",
        "\n",
        "chars = sorted(list(set(text))) # getting all unique chars\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNpN2C7cQypE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "431b52e9-83e8-4242-d551-6b05b1603a23"
      },
      "source": [
        "print(f\"Text length: {len(text)}\")\n",
        "print(f\"Total characters: {len(chars)}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text length: 181846\n",
            "Total characters: 62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWIM_nP_THjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorization\n",
        "# Split data into lengths of 40 chars, transform into boolean array\n",
        "max_len = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - max_len, step):\n",
        "  sentences.append(text[i: i+max_len])\n",
        "  next_chars.append(text[i + max_len])\n",
        "\n",
        "x = np.zeros((len(sentences), max_len, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KLc0r--VlGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "model = tf.keras.models.Sequential([\n",
        "    LSTM(128, input_shape=(max_len, len(chars))),\n",
        "    Dense(len(chars), activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zruuBo6bWXR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsznb9dCWsF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"Helper functions\"\n",
        "\n",
        "# Samples an index from a probability array.\n",
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype(\"float64\")\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "# Function evoked at end of each epoch. Prints generated text.\n",
        "def on_epoch_end(epoch, logs):\n",
        "  print()\n",
        "  print(\"----- Generating text after Epoch: %d\" % epoch)\n",
        "\n",
        "  start_index = random.randint(0, len(text) - max_len - 1)\n",
        "  for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print(\"----- diversity:\", diversity)\n",
        "\n",
        "    generated = \"\"\n",
        "    sentence = text[start_index: start_index + max_len]\n",
        "    generated += sentence\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(400):\n",
        "      x_pred = np.zeros((1, max_len, len(chars)))\n",
        "      for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1\n",
        "      \n",
        "      preds = model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = sample(preds, diversity)\n",
        "      next_char = indices_char[next_index]\n",
        "\n",
        "      generated += next_char\n",
        "      sentence = sentence[1:] + next_char\n",
        "\n",
        "      sys.stdout.write(next_char)\n",
        "      sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "print_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end = on_epoch_end)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek-WLhtIY8be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saves model when loss decreases after each epoch\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=1, save_best_only=True, mode=\"min\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6KbCSU7ZXGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduce learning rate each time learnign plateaus\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=1, min_lr=0.001)\n",
        "\n",
        "callbacks = [print_callback, checkpoint, reduce_lr]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wTKjH8qZwrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f3c2a66-42f9-4ea6-bbd2-885296caaa3b"
      },
      "source": [
        "# Train\n",
        "model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "470/474 [============================>.] - ETA: 0s - loss: 1.3465\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \". no rescue? what, a prisoner? i am even\"\n",
            ". no rescue? what, a prisoner? i am even.\n",
            "  kent. and the he ston me i cannot the horse.\n",
            "     i have his her my stoll, and the heart.\n",
            "     that i have a doge that make not have of fartes\n",
            "     to this lord and make a dost this life,\n",
            "     i storm'd the he still me to this the complete of this complete of this complete of this complete to the to this life,\n",
            "     and for my lord and me the thing and the storm.\n",
            "     i stown of the world make \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \". no rescue? what, a prisoner? i am even\"\n",
            ". no rescue? what, a prisoner? i am even.\n",
            "     you most have not this be right to lest her for have so death of more with then all within.\n",
            "  corn. thou duest still her hall be may not be\n",
            "     to this come that the he be judglest most lies, make him forse and casters.\n",
            "  lear. i serve all the heatt and to thy stoll be\n",
            "     we condelial have my looks are words, who iisher.\n",
            "  kent. then thou dote complete come this old man him.\n",
            "  gon. i hav\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \". no rescue? what, a prisoner? i am even\"\n",
            ". no rescue? what, a prisoner? i am eventer, gon cromituas that tromish spupience\n",
            "tike from him;\n",
            "     i live tore put.\n",
            "  corn. farthil my will? fares his eld i son fartions of cooclition resent her.\n",
            "  torn. you dellow'st hom incound, look!  hand meebactol!\n",
            "  gent. alov! he lonks hast upery sal thou joon.\n",
            "  kent. bray helf.\n",
            "  .  servaden.                                                                                     exeunt.\n",
            "\n",
            "  euc. \n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \". no rescue? what, a prisoner? i am even\"\n",
            ". no rescue? what, a prisoner? i am even;\n",
            "     you are nsseete tham's give.\n",
            "  voncoters mind; fol, with flihims, service of lifes, sach,\n",
            "     no. who rascerack-drive to't destorne, you stoke persu!\n",
            "'p cold on?\n",
            "; fool,  fomlost him corting exit.\n",
            "  alb. eforesparion. he cap me werr not my high sta, suchf,ing.\n",
            "     no you villing now their dirsfor.ntey; yon doss.\n",
            " *os. speep. bryy, intunn buddy, gerces,      when upposes bry?\n",
            "  eda. who i \n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.34697, saving model to weights.hdf5\n",
            "474/474 [==============================] - 74s 156ms/step - loss: 1.3470\n",
            "Epoch 2/5\n",
            "466/474 [============================>.] - ETA: 0s - loss: 1.3038\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"to my sister.\n",
            "  lear. [rises] never, reg\"\n",
            "to my sister.\n",
            "  lear. [rises] never, regan, i shall be not and the duke the duke of cornwall thee the duke the duke the and mad her handed\n",
            "     i have the doon the matter. the to the duke the duke the readanty.\n",
            "                                                                                                                                                                                                                                     \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"to my sister.\n",
            "  lear. [rises] never, reg\"\n",
            "to my sister.\n",
            "  lear. [rises] never, regan, his every hould lart\n",
            "     that be with him his hearts; thou mad my bloodest thou dare his\n",
            "provided by placient.\n",
            "  edg. but my shortld to will offend. where is have says. and befure,\n",
            "     and love the stoll see thou dangers to the best thou hadst to harry lords\n",
            "     that where is the worbend little him formund would see the shorp\n",
            "him\n",
            "     to save the ready to the and theme this\n",
            "     or the foul\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"to my sister.\n",
            "  lear. [rises] never, reg\"\n",
            "to my sister.\n",
            "  lear. [rises] never, regan, fultins he was disnot read most restance, thou, sount,\n",
            "     my sgoperanilar you.\n",
            "  lear. no boy, my wils; sirrear no, of gloucester.\n",
            "  lear. good to a mared the sucu.y of the suughtsy spiese me troit'd gone;\n",
            "     and wedie, and patithine perse with him'd\n",
            "     i will my you ho'se thou aladucutatterly life.\n",
            "     beconst.\n",
            "  lear. blame., wellancuets. who thoug that swally allan laes!\n",
            "     the bun\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"to my sister.\n",
            "  lear. [rises] never, reg\"\n",
            "to my sister.\n",
            "  lear. [rises] never, regan, [bisenngur, then stuh.\n",
            "  lear. say, silldd ditchous. by by, and make\n",
            "thy dogs.\n",
            "  edg. i hald my eyes ston crudgies or rigedd bettes tind of ma--pah[ought copyright fool,\n",
            "     the awher a) ey drry's a mannoubblat us.\n",
            "     my compithry by all tate, 'ngunest\n",
            "     book! pliconsinnole. ; goesuly, hath lofhs\n",
            "     cose, undild to eyes! fooms, foor donetiections statle, wetchyeath-\n",
            "     lady, and fool\n",
            "\n",
            "Epoch 00002: loss improved from 1.34697 to 1.30322, saving model to weights.hdf5\n",
            "474/474 [==============================] - 74s 157ms/step - loss: 1.3032\n",
            "Epoch 3/5\n",
            "467/474 [============================>.] - ETA: 0s - loss: 1.2628\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" comes kent.\n",
            "  alb. produce their bodies\"\n",
            " comes kent.\n",
            "  alb. produce their bodies prose my lord.\n",
            "  glou. he within. i will the father more do sorry see him to the bear my father\n",
            "     most danger and the bear my lord and fortuntial to heart\n",
            "     the bear my lord and the bear my lord and for do some sister\n",
            "     and the most life and the wild the matter.\n",
            "     and the bear and the matter and the best dear not so long and the most man the fool.\n",
            "  glou. i will not the duke of the ma\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" comes kent.\n",
            "  alb. produce their bodies\"\n",
            " comes kent.\n",
            "  alb. produce their bodies and the mistres him patter.\n",
            "     my dear says of the fool.                                                                                  exeunt bry. here hath he my lord a father.\n",
            "     what say and the thie and thee east their commong should reserves\n",
            "     that me not be him in him the foolucus uncbur\n",
            "     man the forter train.\n",
            "  lear. what house from him the hudy. be not will have my logst me,\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" comes kent.\n",
            "  alb. produce their bodies\"\n",
            " comes kent.\n",
            "  alb. produce their bodies new.\n",
            "     we copyotichly, for shill thy\n",
            "wars\n",
            "     for bady'd him horre-         fother.\n",
            "\n",
            " geat. 'tis mepon. to harruch should within,\n",
            "     it, approvoved mechisss of seen this tristrown\n",
            "diben.\n",
            "     his me, fell, apoly mending go edmancy's,\n",
            "     ring in well hollow, a varmed or spain me\n",
            "     chair.\n",
            "  glou. i .am the yoir\n",
            "before with her.\n",
            "  edg. let all break, fernon tohe wasd as, worth in\n",
            "     kin\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" comes kent.\n",
            "  alb. produce their bodies\"\n",
            " comes kent.\n",
            "  alb. produce their bodies a horse!\n",
            "  gent. nowsle. now, marve priblesting descrabted gill!\n",
            "     o ere on my traxs\n",
            "     fortuning toswass. yourllur howlan].\n",
            "  corn. i your -ar to turp till\n",
            "     when a dunderch thy vusb'd mose of blight.] or muck aw.\n",
            "     i ?etrandere the butts dispoituumbor,\n",
            "     thus king herr thougend asdardds you's spry low,\n",
            "     must see hum fifbdidsd hasewarragethoip obost, whatachadiul thy essevited \n",
            "\n",
            "Epoch 00003: loss improved from 1.30322 to 1.26415, saving model to weights.hdf5\n",
            "474/474 [==============================] - 74s 156ms/step - loss: 1.2642\n",
            "Epoch 4/5\n",
            "468/474 [============================>.] - ETA: 0s - loss: 1.2377\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"\n",
            "  glou. why so earnestly seek you to pu\"\n",
            "\n",
            "  glou. why so earnestly seek you to purposes the better to the fool ether\n",
            "     that i should have that the prove our son me\n",
            "     that i shall be one our seech the best and the poor the powerle come in this\n",
            "the\n",
            "     that i shall be one our sone that i was not be\n",
            "     that i should have so long a do shapain\n",
            "     that this the poor the heart one this fortid him. that in this treepiend that in the poor this the poor the power,\n",
            "     where \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"\n",
            "  glou. why so earnestly seek you to pu\"\n",
            "\n",
            "  glou. why so earnestly seek you to purpose.\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                         \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"\n",
            "  glou. why so earnestly seek you to pu\"\n",
            "\n",
            "  glou. why so earnestly seek you to purpess all-\n",
            "     to him drang copurer condition. .lou and mat she somessapan.\n",
            "     you filidy. yet have opurar p[there's swe goner\n",
            "this\n",
            "' bese?\n",
            "     make in th' eldi'd to thing against yet\n",
            "     of the decere ose the field your word,\n",
            "     swom since that hears, -                                                   ! so o mistre but nais wordraw one! panty strikenge is king. thell, the braught-\n",
            "     to\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"\n",
            "  glou. why so earnestly seek you to pu\"\n",
            "\n",
            "  glou. why so earnestly seek you to puttinie ene,\n",
            "     oner that regiting, whtreve even of corksim.               the bes.y\n",
            "  downt his kingless?.\n",
            "\n",
            "  glou. how shacbxitgun fime let him ton i gatiort\n",
            "readammblate of mish-\n",
            "     make is thine a, sister'd gone, whosom such her ever\n",
            "     hast come seebs; he replaceingrows,\n",
            "     murchinglite.\n",
            "\n",
            "  kent. 'tis not bester inclatimiere. tought some'p\n",
            "     no, will befurn.\n",
            "  cor. o, scwe not willl\n",
            "\n",
            "Epoch 00004: loss improved from 1.26415 to 1.23754, saving model to weights.hdf5\n",
            "474/474 [==============================] - 74s 157ms/step - loss: 1.2375\n",
            "Epoch 5/5\n",
            "472/474 [============================>.] - ETA: 0s - loss: 1.2103\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"eds of volunteers and donations*\n",
            "\n",
            "inform\"\n",
            "eds of volunteers and donations*\n",
            "\n",
            "informath of the wild to thee.\n",
            "  lear. i have the warm there is the commendion of thine of the was i an in the exielit in the comminds of the warm\n",
            "     that i have see the thing in the dight in the fiend to thee in the fiend to the tention of thing in the exienient and man,\n",
            "     the wild he man him a sead the thing in the tring it made the duke thee thee a string in the exielit in the tring of the was i\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"eds of volunteers and donations*\n",
            "\n",
            "inform\"\n",
            "eds of volunteers and donations*\n",
            "\n",
            "informath,\n",
            "     that are not both his lust a daughter so many. in his from\n",
            "his midece, if thou doon do the bessiall nead. hears,\n",
            "     that the with my strikent with me to the in the plage, for thee,\n",
            "     to thou due his cornwall.\n",
            "     not see the wears and the inaughty in the exiere to their damgeders heart;\n",
            "     and we thine to such him our daughter in content\n",
            "     that thou have my lords me the projec\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"eds of volunteers and donations*\n",
            "\n",
            "inform\"\n",
            "eds of volunteers and donations*\n",
            "\n",
            "informan and maulh[of. i have a securence\n",
            "ain,\n",
            "     so huspiss mean nead! peach the camons beeate,\n",
            "     there is not see me; siyfor pretace of cornwall live dessited defeisd\n",
            "\n",
            "    what proy parpeted in a lit you have give in the shorn.\n",
            "  fool. thine and man. him ty me my advient,\n",
            "\n",
            "     to dinnort. yen, give i asdome th' are you you beentless'd you.\n",
            "     sir, though there's hopen my fatherge my lord.\n",
            "  ed\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"eds of volunteers and donations*\n",
            "\n",
            "inform\"\n",
            "eds of volunteers and donations*\n",
            "\n",
            "informar? yen.\n",
            "  corn. firry, glouest it lear firnd fir his papite\n",
            "that,\n",
            "and nobles a king\n",
            "of thy lov's\n",
            "     and hear fhy detirs pelitivile lead speepe.\n",
            "     whorswaroun make that traidel servest.\n",
            "  gon. tands, kerg me him, weer.- by cordeanain, we knowlin than\n",
            "] as that.\n",
            "  glou. with, throt'd atfir my taidd! [to as to scure\n",
            "     you will uponest thou, got'd deleshid offecble.\n",
            "         whom \n",
            "himst see d\n",
            "\n",
            "Epoch 00005: loss improved from 1.23754 to 1.21033, saving model to weights.hdf5\n",
            "474/474 [==============================] - 75s 158ms/step - loss: 1.2103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc53825af60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdQ_YnmsboO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate text\n",
        "# Takes random start idx, uses next 40 chars to make predictions\n",
        "def generate_text(length, diversity):\n",
        "  start_index = random.randint(0, len(text) - max_len - 1)\n",
        "\n",
        "  generated = \"\"\n",
        "  sentence = text[start_index: start_index + max_len]\n",
        "  generated += sentence\n",
        "\n",
        "  for i in range(length):\n",
        "    x_pred = np.zeros((1, max_len, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      x_pred[0, t, char_indices[char]] = 1\n",
        "    \n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds, diversity)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "\n",
        "  return generated"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQbiwy48cpDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8f075eef-7e6e-48a4-d7ba-d2a09acf84ed"
      },
      "source": [
        "print(generate_text(500, 0.2))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sopher.\n",
            "     what is the cause of thunder to the time of all the pain the commendion of the warm\n",
            "     to the to thee the thing in the exit and for souce as may be\n",
            "     that the best to dear the duke of thine is proved it me,\n",
            "     that the cappose the with the thing in the complete him for your eyise well dear the duke of cornwall not here is the put's electronic and wast\n",
            "     that he that the warm there in the warm\n",
            "     to here is the thing in the tempetion the paties of thine is proves\n",
            "     that i have the that are the commendithing \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}